{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Feature Matrix\n",
    "The following two lists contain the features chosen for the naive (user based) and graph based feature matrixes. We create three feature matrixes. One with just user features, one with graph features, and then a final one with a combination of the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./data/user_filled.pickle\", \"rb\") as file:\n",
    "    users = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = [\n",
    "    \"statuses_count\",\n",
    "    \"friends_count\",\n",
    "    \"favourites_count\",\n",
    "    \"age\",\n",
    "    \"activity_statuses\",\n",
    "    \"activity_friends\"\n",
    "]\n",
    "\n",
    "graph_features = [\n",
    "    \"role\",\n",
    "    \"eigenvector\",\n",
    "    \"closeness\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_naive = []\n",
    "X_graph = []\n",
    "X_hybrid = []\n",
    "Y = []\n",
    "\n",
    "for user in users:\n",
    "    x_naive = []\n",
    "    x_graph = []\n",
    "    x_hybrid = []\n",
    "    \n",
    "    for feature in user_features:\n",
    "        x_naive.append(int(user[feature]) if user[feature] else 0)\n",
    "        x_hybrid.append(int(user[feature]) if user[feature] else 0)\n",
    "    for graph_feature in graph_features:\n",
    "        x_graph.append(user[graph_feature])\n",
    "        x_hybrid.append(user[graph_feature])\n",
    "        \n",
    "    X_naive.append(x_naive)\n",
    "    X_graph.append(x_graph)\n",
    "    X_hybrid.append(x_hybrid)\n",
    "    Y.append(int(user[\"class\"] == \"bot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Classifiers\n",
    "The first step is to train 10 simple classifiers from SKLearn. This is just to get a baseline comparison before training more complex models in order to see where we stand in terms of possible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=10, max_features=3),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "naive_scores = []\n",
    "\n",
    "for name, classifier in zip(names, classifiers): \n",
    "    \n",
    "    X = StandardScaler().fit_transform(X_naive)\n",
    "    N_X_train, N_X_test, N_y_train, N_y_test = \\\n",
    "        train_test_split(X_naive, Y, test_size=.2, random_state=42)\n",
    "    clf = classifier.fit(N_X_train, N_y_train)\n",
    "    naive_scores.append(clf.score(N_X_test, N_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_scores = []\n",
    "\n",
    "for name, classifier in zip(names, classifiers): \n",
    "    X = StandardScaler().fit_transform(X_graph)\n",
    "    G_X_train, G_X_test, G_y_train, G_y_test = \\\n",
    "        train_test_split(X_graph, Y, test_size=.2, random_state=42)\n",
    "\n",
    "    clf = classifier.fit(G_X_train, G_y_train)\n",
    "    graph_scores.append(clf.score(G_X_test, G_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_scores = []\n",
    "\n",
    "for name, classifier in zip(names, classifiers): \n",
    "    X = StandardScaler().fit_transform(X_hybrid)\n",
    "    H_X_train, H_X_test, H_y_train, H_y_test = \\\n",
    "        train_test_split(X_hybrid, Y, test_size=.2, random_state=42)\n",
    "\n",
    "    clf = classifier.fit(G_X_train, G_y_train)\n",
    "    hybrid_scores.append(clf.score(G_X_test, G_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Classification Results\n",
    "These results are pretty promising. These show that in all cases the graph based features are at least comparable to their counterparts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Name             </th><th style=\"text-align: right;\">  Naive Score</th><th style=\"text-align: right;\">  Graph Score</th><th style=\"text-align: right;\">  Hybrid Score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Nearest Neighbors</td><td style=\"text-align: right;\">     0.715686</td><td style=\"text-align: right;\">     0.686275</td><td style=\"text-align: right;\">      0.686275</td></tr>\n",
       "<tr><td>Gaussian Process </td><td style=\"text-align: right;\">     0.696078</td><td style=\"text-align: right;\">     0.696078</td><td style=\"text-align: right;\">      0.696078</td></tr>\n",
       "<tr><td>Decision Tree    </td><td style=\"text-align: right;\">     0.745098</td><td style=\"text-align: right;\">     0.705882</td><td style=\"text-align: right;\">      0.696078</td></tr>\n",
       "<tr><td>Random Forest    </td><td style=\"text-align: right;\">     0.823529</td><td style=\"text-align: right;\">     0.666667</td><td style=\"text-align: right;\">      0.676471</td></tr>\n",
       "<tr><td>Neural Net       </td><td style=\"text-align: right;\">     0.686275</td><td style=\"text-align: right;\">     0.696078</td><td style=\"text-align: right;\">      0.696078</td></tr>\n",
       "<tr><td>AdaBoost         </td><td style=\"text-align: right;\">     0.754902</td><td style=\"text-align: right;\">     0.686275</td><td style=\"text-align: right;\">      0.686275</td></tr>\n",
       "<tr><td>Naive Bayes      </td><td style=\"text-align: right;\">     0.735294</td><td style=\"text-align: right;\">     0.686275</td><td style=\"text-align: right;\">      0.686275</td></tr>\n",
       "<tr><td>QDA              </td><td style=\"text-align: right;\">     0.72549 </td><td style=\"text-align: right;\">     0.676471</td><td style=\"text-align: right;\">      0.676471</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "import numpy as np\n",
    "\n",
    "table = np.array([names, naive_scores, graph_scores, hybrid_scores]).T\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html', headers=[\"Name\", \"Naive Score\", \"Graph Score\", \"Hybrid Score\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Feature Set  </th><th style=\"text-align: right;\">  Accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>User         </td><td style=\"text-align: right;\">  0.686275</td></tr>\n",
       "<tr><td>Graph        </td><td style=\"text-align: right;\">  0.701961</td></tr>\n",
       "<tr><td>Hybrid       </td><td style=\"text-align: right;\">  0.768627</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = [\"User\", \"Graph\", \"Hybrid\"]\n",
    "features = [X_naive, X_graph, X_hybrid]\n",
    "accuracies = []\n",
    "\n",
    "for X, name in zip(features, names):\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, Y, test_size=.2, random_state=42)\n",
    "\n",
    "    X_Train = np.array(X_train)\n",
    "    y_Train = np.array(y_train)\n",
    "    X_Test= np.array(X_test)\n",
    "    y_Test=np.array(y_test)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=len(X_train[0]), activation='relu')) # input_dim = 6 for Naive and 5 for Graph\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_Train, y_Train, epochs=350, batch_size=10, verbose=0)\n",
    "\n",
    "    _, accuracy = model.evaluate(X_Test, y_Test, verbose=0)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "table = np.array([names, accuracies]).T\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html', headers=[\"Feature Set\", \"Accuracy\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Feature Set  </th><th style=\"text-align: right;\">  Accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>User         </td><td style=\"text-align: right;\">   76.0784</td></tr>\n",
       "<tr><td>Graph        </td><td style=\"text-align: right;\">   69.8039</td></tr>\n",
       "<tr><td>Hybrid       </td><td style=\"text-align: right;\">   78.0392</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for X, name in zip(features, names):\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, Y, test_size=.2, random_state=42)\n",
    "\n",
    "    X_Train = np.array(X_train)\n",
    "    y_Train = np.array(y_train)\n",
    "    X_Test= np.array(X_test)\n",
    "    y_Test=np.array(y_test)\n",
    "\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_Train, y_Train)\n",
    "\n",
    "    y_pred = model.predict(X_Test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "\n",
    "    accuracies.append(accuracy_score(y_Test, predictions) * 100.0)\n",
    "    \n",
    "table = np.array([names, accuracies]).T\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html', headers=[\"Feature Set\", \"Accuracy\"])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
